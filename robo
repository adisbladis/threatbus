#!/usr/bin/env python

import argparse
import asyncio
import coloredlogs
import confuse
import datetime
from enum import Enum, auto
import functools
import json
import logging
import os
from shutil import which
import sys
from typing import NamedTuple
import urllib.parse

POLL_INTERVAL = 0.05
PYTHON_3_6 = (3, 6, 6, 'final', 0)
PYTHON_3_7 = (3, 7)

def make_excerpt(string, max_len=300):
    result = string[:max_len]
    if len(string) > max_len:
        result += "..."
    return result

def str_escape(x):
    return '"' + x.replace('"','\\"') + '"'

def async_loop():
    if sys.version_info <= PYTHON_3_6:
        return asyncio.get_event_loop()
    else:
        assert sys.version_info >= PYTHON_3_7
        return asyncio.get_running_loop()

def async_run(f):
    if sys.version_info <= PYTHON_3_6:
        loop = asyncio.get_event_loop()
        loop.run_until_complete(f())
        loop.close()
    else:
        asyncio.run(f())

def async_create_task(f):
    if sys.version_info <= PYTHON_3_6:
        return asyncio.ensure_future(f)
    else:
        return asyncio.create_task(f)

def asyncify(f):
    @functools.wraps(f)
    async def coroutine(*args, **kwargs):
        partial = functools.partial(f, *args, **kwargs)
        return await async_loop().run_in_executor(None, partial)
    return coroutine

async def spawn(*args):
    """Spawns a process asynchronously."""
    proc = await asyncio.create_subprocess_exec(
        *args,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE)
    stdout, stderr = await proc.communicate()
    logger = logging.getLogger("robo")
    logger.debug(stderr.decode().strip())
    return stdout.decode().strip()

class Intelligence(NamedTuple):
    id: str         # A unique identifier (within the intel source's context).
    type: str       # The type of intelligence.
    value: str      # The value of the item.
    data: str       # The raw data as given by the source
    source: str     # The origin of the intelligence.
    def __repr__(self):
        return f"({self.id}, {self.type}, {self.value}, {self.source})"

class Action(Enum):
    ADD = auto()
    EDIT = auto()
    REMOVE = auto()

def make_action(x):
    if x == "add":
        return Action.ADD
    if x == "edit":
        return Action.EDIT
    if x == "delete" or x == "remove":
        return Action.REMOVE

def misp_to_zeek_intel_type(intel_type):
    """Translates type names of internal intel to names in Zeek's intel
    framework."""
    # TODO: complete mapping MISP types to Zeek types.
    table = {
        "ip-src": "ADDR",
        "ip-dst": "ADDR",
        "domain": "DOMAIN",
        "email-dst": "EMAIL",
        "email-src": "EMAIL",
        "email-reply-to": "EMAIL",
        "hostname": "DOMAIN",
        "url": "URL",
        "uri": "URL",
        "x509-fingerprint-md5": "CERT_HASH",
        "x509-fingerprint-sha1": "CERT_HASH",
        "x509-fingerprint-sha256": "CERT_HASH",
    }
    return table[intel_type]

class MISP:
    def __init__(self, config):
        self.config = config
        self.logger = logging.getLogger("robo.misp")
        if config.zmq and config.kafka:
            self.logger.critical("cannot have both 0mq and Kafka configured")
        elif not config.zmq and not config.kafka:
            self.logger.critical("need intel either from Kafka or 0mq")
        if config.zmq:
            import zmq
            from zmq.asyncio import Context
            zmq_url = f"tcp://{config.zmq.host}:{config.zmq.port}"
            self.logger.info(f"connecting to MISP 0mq socket at {zmq_url}")
            context = Context.instance()
            socket = context.socket(zmq.SUB)
            socket.connect(zmq_url)
            socket.setsockopt(zmq.SUBSCRIBE, b"")
            async def generate():
                try:
                    while True:
                        msg = await socket.recv()
                        topic, _, payload = msg.decode("utf-8").partition(" ")
                        # Filter out heartbeats.
                        if topic == "misp_json_self":
                            uptime = int(json.loads(payload)["uptime"])
                            delta = datetime.timedelta(seconds=uptime)
                            self.logger.debug("received 0mq keep-alive (uptime "
                                         "{:0>8})".format(str(delta)))
                            continue
                        if topic != "misp_json_attribute":
                            continue
                        # Parse the payload.
                        data = json.loads(payload)
                        excerpt = make_excerpt(json.dumps(data))
                        self.logger.debug(f"got attribute via 0mq: {excerpt}")
                        return data
                except:
                    socket.disconnect(zmq_url)
                    raise
            self.generator = generate
        elif config.kafka:
            from confluent_kafka import Consumer, KafkaError
            self.logger.info("subscribing to MISP Kafka at topic "
                        f"{config.kafka.attribute_topic}")
            self.logger.debug(f"launching Kafka with {config.kafka.config}")
            consumer = Consumer(config.kafka.config)
            consumer.subscribe([config.kafka.attribute_topic])
            @asyncify
            def generate():
                try:
                    while True:
                        msg = consumer.poll(POLL_INTERVAL)
                        if msg is None:
                            continue
                        if msg.error():
                            if msg.error().code() != KafkaError._PARTITION_EOF:
                                self.logger.error(f"got Kafka error: {msg.error()}")
                            continue
                        data  = json.loads(msg.value())
                        excerpt = make_excerpt(json.dumps(data))
                        self.logger.debug(f"got Kafka message: {excerpt}")
                        return data
                except:
                    self.logger.debug("leaving Kafka group and committing offsets")
                    consumer.close()
                    raise
            self.generator = generate
        assert self.generator
        # Connect to MISP instance via API.
        api_key = None
        if "MISP_API_KEY" in os.environ:
            api_key = os.environ['MISP_API_KEY']
        elif config.rest.api_key:
            api_key = config.rest.api_key
        else:
            self.logger.critical("no MISP API key found: use MISP_API_KEY "
                                 "environment variable or config file")
        self.logger.info(f"connecting to MISP REST API at {config.rest.url}")
        try:
            self.misp = pymisp.PyMISP(config.rest.url, config.rest.api_key,
                                      ssl=config.rest.ssl)
        except pymisp.PyMISPError:
            self.logger.critical("connection refused while trying to connect "
                                 f"to {config.rest.url}")

    async def intel(self):
        """Generates the next intelligence item."""
        while True:
            data = await self.generator()
            assert data
            attr = data["Attribute"]
            action = make_action(data["action"])
            to_ids = attr["to_ids"]
            if action == Action.ADD and not to_ids:
                self.logger.debug(f"ignoring new attribute {attr['id']} "
                                  "without IDS flag")
                continue
            if action == Action.EDIT and not to_ids:
                self.logger.debug(f"translating edit of attribute {attr['id']} "
                                  "without IDS flag into removal")
                action = Action.REMOVE

            self.logger.debug(f"got {action.name} for intel {attr['id']}")
            return (action, MISP.make_intel_from_attribute(attr))

    async def report(self, id, time_seen):
        """Reports intelligence as (true-positive) sighting."""
        x = pymisp.MISPSighting()
        x.from_dict(id=id, source="VAST", type="0", timestamp=time_seen)
        ts = datetime.datetime.utcfromtimestamp(time_seen)
        self.logger.debug(f"reporting intel {id} seen at "
                          f"{ts.strftime('%Y-%m-%d %H:%M:%S')}")
        self.misp.set_sightings(x)

    def remove_ids_flag(self, attr_id):
        """Removes the IDS flag from noisy attributes."""
        self.misp.update_attribute(attr_id, {"id": attr_id, "to_ids": False})

    async def snapshot(self):
        data = None
        self.logger.debug("requesting for snapshot with search: "
                          f"{self.config.snapshot.search.items()}")
        if self.config.snapshot.raw:
            return_format = { "returnFormat": "json" }
            params = self.config.snapshot.search
            data = await self.__query({**return_format, **params})
        else:
            data = await self.__search(**self.config.snapshot.search)
        assert data
        attrs = data["response"]["Attribute"]
        return [MISP.make_intel_from_attribute(x) for x in attrs]

    @asyncify
    def __search(self, **kwargs):
        """Performs a search over MISP attributes"""
        return self.misp.search(controller="attributes", **kwargs)

    @asyncify
    def __rest_search(self, query):
        """Performs a search over MISP attributes via the internal REST API"""
        return self.misp._PyMISP__query("restSearch", query,
                                        controller="attributes")

    @staticmethod
    def make_intel_from_attribute(attr):
        return Intelligence(
            id=attr["id"],
            type=attr["type"],
            value=attr["value"],
            data=attr,
            source="misp")

class VAST:
    def __init__(self, config):
        self.logger = logging.getLogger("robo.vast")
        self.app = config.executable
        self.window = config.time_window
        self.max_results = config.max_results
        self.logger.debug(f"capping VAST results at '{self.max_results}' events")

    def make_expression(self, intel):
        """Creates a VAST expression from an intel item."""
        # FIXME: type queries currently prevent this from working.
        #filter = '#type == "zeek::conn"'
        #if self.window:
        #    filter = f"#time > {self.window} ago && {filter}"
        #pred = VAST.make_predicate(intel.type, [intel.value])
        #return f'{filter} && {pred}'
        return VAST.make_predicate(intel.type, [intel.value])

    async def status(self):
        try:
            return json.loads(await spawn(self.app, "status"))
        except json.decoder.JSONDecodeError:
            self.logger.critical(f"failed to connect to remote VAST node")
        except FileNotFoundError:
            self.logger.critical(f"could not find {self.app} in PATH")

    async def export(self, expr, window=None):
        self.logger.debug(f"spawning {self.app} process for expression {expr}")
        stdout = await spawn(self.app, "export", "-e", str(self.max_results),
                             "json", expr)
        return stdout.splitlines()

    def path(self):
        """Retrieves the full path to the VAST binary"""
        return self.app

    @staticmethod
    def make_conjunction(xs):
        return "({})".format(" && ".join(xs))

    @staticmethod
    def make_disjunction(xs):
        return "({})".format(" || ".join(xs))

    @staticmethod
    def make_predicate(intel_type, values):
        assert values
        # Combine singleton values into a set query.
        def condense(lhs, rhs):
            if len(rhs) == 1:
                return f"{lhs} == {rhs[0]}"
            else:
                return f"{lhs} in {{{', '.join(rhs)}}}"
        # IP addresses
        if intel_type in ["ip-src", "ip-dst"]:
            return condense(":addr", values)
        # URLs
        elif intel_type in ["url", "uri"]:
            def make_http_log_expr(x):
                result = urllib.parse.urlsplit(x)
                host = result.hostname
                path = result.path
                if not host and path and path[0] != "/":
                    # If there is no protocol in the URI, then the "host" part will
                    # be prepended to "path". We're "fixing" this behavior by
                    # manually splitting at the first "/".
                    host, path = tuple(path.split("/", 1))
                    path = "/" + path # bring back leading slash
                host = f"host == {str_escape(host)}" if host else None
                path = f"uri == {str_escape(path)}" if path else None
                if host and path:
                    return VAST.make_conjunction([host, path])
                if host:
                    return host
                if path:
                    return path
                return None
            return VAST.make_disjunction(map(make_http_log_expr, values))
        # Domains
        elif intel_type == "domain":
            return condense("host", list(map(str_escape, values)))
        # Other
        elif intel_type == "http-method":
            return condense("method", list(map(str_escape, values)))
        else:
            self.logger.critical("unsupported intel type:", intel_type)

class Zeek:
    def __init__(self, config):
        self.logger = logging.getLogger("robo.zeek")
        self.config = config
        self.endpoint = broker.Endpoint()
        self.subscriber = self.endpoint.make_subscriber([config.topic])
        self.logger.debug(f"creating subscriber for topic '{config.topic}'")
        self.logger.info("establishing peering with Zeek at "
                         f"{config.host}:{config.port}")
        self.endpoint.peer(config.host, config.port)
        self.logger.debug("established peering succesfully")

    def add_intel(self, intel):
        """Forwards intelligence to Zeek"""
        self.logger.debug(f"forwarding intel to Zeek: {intel}")
        event = broker.bro.Event(
            "Tenzir::add_intel",
            misp_to_zeek_intel_type(intel.type),
            intel.value,
            intel.id)
        self.endpoint.publish(self.config.topic, event)

    def remove_intel(self, intel):
        """Forwards intelligence to Zeek"""
        self.logger.debug(f"deleting intel from Zeek: {intel}")
        event = broker.bro.Event(
            "Tenzir::remove_intel",
            misp_to_zeek_intel_type(intel.type),
            intel.value,
            intel.id)
        self.endpoint.publish(self.config.topic, event)

    def dump_intel(self, source):
        """Retrieves an intel snapshot from Zeek"""
        self.logger.debug(f"requesting intel snapshot from Zeek")
        request = broker.bro.Event("Tenzir::intel_snapshot_request", source)
        self.endpoint.publish(self.config.topic, request)

    async def get(self):
        """Retrieves an event from Zeek via Broker"""
        while True:
            if self.subscriber.available():
                topic, data = self.subscriber.get()
                event = broker.bro.Event(data)
                self.logger.debug(f"{topic} -> event {event.name()}{event.args()}")
                return event
            else:
                # This is a poor workaround for the lack of asynchrony in the
                # Broker Python bindings. For some weird reason, we cannot just
                # run this function in the executor because it blocks all other
                # coroutines. So now we do polling with asynchronous sleepping
                # at fixed rate.
                await asyncio.sleep(POLL_INTERVAL)

    def put(self, event_name, *args):
        """Sends an event to Zeek via Broker"""
        event = broker.bro.Event(event_name, *args)
        self.endpoint.publish(self.config.topic, event)

class Controller:
    def __init__(self, vast, misp, zeek):
        self.logger = logging.getLogger("robo.controller")
        self.vast = vast
        self.misp = misp
        self.zeek = zeek
        # List of intel IDs that we have received from Zeek and forwarded to
        # MISP for IDS flag removal. Once MISP removes the IDS flag, we will
        # receive an updated attribute without IDS flag. We ignore such an
        # update because Zeek already deleted the intel item along with
        # reporting it as noisy.
        self.noisy_intel = []

    async def run(self):
        self.logger.debug("starting main loop")
        zeek = None
        misp = None
        while True:
            if not zeek:
                self.logger.debug("scheduling Zeek task")
                zeek = async_create_task(self.zeek.get())
            if not misp:
                self.logger.debug("scheduling MISP task")
                misp = async_create_task(self.misp.intel())
            done, pending = await asyncio.wait(
                [zeek, misp],
                timeout=1,
                return_when=asyncio.FIRST_COMPLETED)
            if zeek in done:
                event = zeek.result()
                zeek = None
                if event.name() == "Tenzir::intel_snapshot_request":
                    self.logger.debug("retrieving snapshot from MISP")
                    snapshot = await self.misp.snapshot()
                    self.logger.debug("sending Zeek snapshot from MISP with "
                                      f"{len(snapshot)} intel items")
                    f = lambda x: misp_to_zeek_intel_type(x.type)
                    items = [[x.id, f(x), x.value] for x in snapshot]
                    self.zeek.put("Tenzir::intel_snapshot_reply", items)
                elif event.name() == "Tenzir::intel_snapshot_reply":
                    assert len(event.args()) == 1
                    def make_intel(xs):
                        assert len(xs) == 3
                        return {
                            "id": int(xs[0]),
                            "type": xs[1],
                            "value": xs[2]
                        }
                    snapshot = [make_intel(xs) for xs in event.args()[0]]
                    print(json.dumps(snapshot))
                    sys.exit(0)
                elif event.name() == "Tenzir::intel_report":
                    timestamp, ids = event.args()
                    assert ids
                    self.logger.info(f"Zeek saw intel {ids} at {timestamp}")
                    if self.misp:
                        self.logger.debug(f"reporting {len(ids)} sightings "
                                          "from Zeek to MISP")
                        ts = int(timestamp.timestamp())
                        for id in ids:
                            await self.misp.report(id, ts)
                elif event.name() == "Tenzir::noisy_intel_report":
                    assert len(event.args()) == 2
                    attr_id, n = event.args()
                    self.logger.info("removing IDS flag from noisy attribute "
                                     f"{attr_id} with {n.value} matches/sec")
                    self.misp.remove_ids_flag(attr_id)
                    self.noisy_intel.append(attr_id)
            if misp in done:
                action, intel = misp.result()
                misp = None
                if action in [Action.ADD, Action.EDIT]:
                    if self.vast:
                        expr = self.vast.make_expression(intel)
                        results = await self.vast.export(expr)
                        self.logger.debug(f"reporting {len(results)} sightings "
                                          "from VAST to MISP")
                        for result in results:
                            self.logger.debug(result)
                            record = json.loads(result)
                            if "ts" not in record:
                                self.logger.critical(
                                    "no 'ts' column in Zeek log")
                            timestamp = int(record["ts"])
                            await self.misp.report(intel.id, timestamp)
                    if self.zeek:
                        self.zeek.add_intel(intel)
                elif action == Action.REMOVE:
                    if self.zeek:
                        if intel.id in self.noisy_intel:
                            self.logger.debug(f"ignorying noisy intel update")
                            self.noisy_intel.remove(intel.id)
                        else:
                            self.zeek.remove_intel(intel)

# -- main ---------------------------------------------------------------------

# The valid schema for the configuration.
log_levels = ['CRITICAL', 'ERROR', 'WARNING', 'INFO', 'DEBUG']

# Allows a config field to be optional. For details, see the discussion at:
# https://github.com/sampsyo/confuse/issues/45
class OptionalMappingTemplate(confuse.MappingTemplate):
    def __init__(self, mapping):
        subtemplates = {}
        for key, typ in mapping.items():
            template = confuse.as_template(typ)
            template.default = None
            subtemplates[key] = template
        self.subtemplates = subtemplates
        self.default = None
    def value(self, view, template=None):
        out = confuse.AttrDict()
        for key, typ in self.subtemplates.items():
            x = typ.value(view[key], self)
            if x:
                out[key] = x
        return out if out else None

def optional(xs):
    return OptionalMappingTemplate(xs)

template = {
    'logger': {
        'console': bool,
        'file': bool,
        'filename': str,
        'console_verbosity': confuse.Choice(log_levels),
        'file_verbosity': confuse.Choice(log_levels),
    },
    'producers': {
        'misp': {
            'rest': {
                'url': str,
                'ssl': bool,
                'api_key': str,
            },
            'zmq': optional({
                'host': str,
                'port': int,
            }),
            'kafka': optional({
                'attribute_topic': str,
                'config': dict,
            }),
            'snapshot': {
                'raw': bool,
                'search': dict,
            },
        },
    },
    'consumers': {
        'zeek': optional({
            'host': str,
            'port': int,
            'topic': str,
        }),
        'vast': optional({
            'executable': str,
            'max_results': int,
            'time_window': str,
        }),
    },
}

async def main():
    """The main function"""
    # Setup configuration
    lazy_config = confuse.LazyConfig('RoboInvestigator', __name__)
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--config',
        '-c',
        help='path to a configuration file')
    parser.add_argument(
        '--quiet',
        '-q',
        dest='logger.console',
        action='store_false',
        help='do not log to console')
    parser.add_argument(
        "--misp-rest-uri",
        "-m",
        dest="producers.misp.rest.url",
        help="The REST API host of the MISP instance")
    parser.add_argument(
        "--misp-zmq-host",
        "-0",
        dest="producers.misp.zmq.host",
        help="The ZMQ host configured with MISP")
    parser.add_argument(
        "--zeek-host",
        "-z",
        dest="consumers.zeek.host",
        help="The Zeek host running the integration scripts")
    parser.add_argument(
        "--dump-zeek-intel",
        action='store_true',
        help="connects to Zeek and dumps all intel")
    args = parser.parse_args()
    if args.config:
        lazy_config.set_file(args.config)
    lazy_config.set_args(args, dots=True)
    config = lazy_config.get(template)
    # Setup logging.
    logger = logging.getLogger('robo')
    logger.setLevel(logging.DEBUG) # FIXME: compute min(file, console)
    fmt = "%(asctime)s %(levelname)-8s [%(name)s] %(message)s"
    colored_formatter = coloredlogs.ColoredFormatter(fmt)
    plain_formatter = logging.Formatter(fmt)
    if config.logger.file:
        fh = logging.FileHandler(config.logger.filename)
        fh.setLevel(config.logger.file_verbosity)
        fh.setFormatter(plain_formatter)
        logger.addHandler(fh)
    if config.logger.console:
        ch = logging.StreamHandler()
        ch.setLevel(config.logger.console_verbosity)
        ch.setFormatter(colored_formatter)
        logger.addHandler(ch)
    class ShutdownHandler(logging.Handler):
        def emit(self, record):
            logging.shutdown()
            sys.exit(1)
    sh = ShutdownHandler(level=50)
    sh.setFormatter(colored_formatter)
    logger.addHandler(sh)
    # Sanity check configuration. This should ideally move into the template
    # itself.
    if not config.producers.misp:
        logger.critical("MISP intel producer not configured")
    if not (config.consumers.vast or config.consumers.zeek):
        logger.critical("no intel consumer provided; configure VAST or Zeek")
    # Setup VAST
    vast = None
    if config.consumers.vast:
        executable = config.consumers.vast.executable
        if not executable:
            logger.critical(f"could not find VAST at {executable}")
        vast = VAST(config.consumers.vast)
        vast_status = await vast.status()
        vast_threads = vast_status['system']['worker-threads']
        logger.info(f"found VAST running with {vast_threads} threads")
    # Setup MISP.
    misp = None
    if config.producers.misp:
        globals()["pymisp"] = __import__("pymisp")
        misp = MISP(config.producers.misp)
    # Connect to Zeek.
    zeek = None
    if config.consumers.zeek:
        globals()["broker"] = __import__("broker")
        globals()["broker.bro"] = __import__("broker.bro")
        zeek = Zeek(config.consumers.zeek)
        if args.dump_zeek_intel:
            zeek.dump_intel("tenzir")
    # Create controller.
    controller = Controller(vast, misp, zeek)
    await controller.run()

if __name__ == '__main__':
    async_run(main)
